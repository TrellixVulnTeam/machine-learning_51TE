{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network\n",
    "\n",
    "Building a two layer Neural Network using the Sigmoid activation function\n",
    "\n",
    "### Neural Network Training\n",
    "\n",
    "The output of a simple 2 layer network is:\n",
    "\n",
    "$\\hat{y} = \\sigma(W_2 \\sigma(W_1x + b_1) + b_2)$\n",
    "\n",
    "Training the model will correct the weights and biases\n",
    "\n",
    "### Training Process\n",
    "\n",
    "**Feedforward**: Calculating the predicted output $\\hat{y}$  \n",
    "**Backpropagation**: Updating the weights and biases\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "Using **sum-of-squares error** as loss function\n",
    "\n",
    "*Sum-of-Squares Error* $= \\sum_{i=1}^n(y - \\hat{y})^2$\n",
    "\n",
    "Differences are squared to measure the sum of absolute values. Objective of training is to minimize the loss function\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "**Gradient Descent**: Update the weights and biases using the derivative of the loss function\n",
    "\n",
    "Need **chain rule** to calculate the derivative of the loss function with respect to the weights and biases\n",
    "\n",
    "$Loss(y, \\hat{y}) = \\sum_{i=1}^n(y - \\hat{y})^2$\n",
    "\n",
    "$\\frac{\\partial Loss(y, \\hat{y})}{\\partial W} = \\frac{\\partial Loss(y, \\hat{y})}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial z} * \\frac{\\partial z}{\\partial W}$, where $z = Wx + b$\n",
    "\n",
    "$= 2(y - \\hat{y}) * \\frac{\\partial \\hat{y}}{\\partial z} * x = 2(y - \\hat{y}) * z(1 - z) * x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Function\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + np.exp(-t))\n",
    "\n",
    "def sigmoid_derivative(p):\n",
    "    return p * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network class\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1], 4)\n",
    "        self.weights2 = np.random.rand(4, 1)\n",
    "        self.y = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "        \n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        return self.output\n",
    "        \n",
    "    def backprop(self):\n",
    "        # Application of chain rule to find derivative of loss function\n",
    "        d_weights2 = np.dot(self.layer1.T, (2 * (self.y - self.output) * sigmoid_derivative(self.output)))\n",
    "        d_weights1 = np.dot(self.input.T, (np.dot(2 * (self.y - self.output) \n",
    "                                * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
    "        \n",
    "        # Update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.output = self.feedforward()\n",
    "        self.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interation # 0\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.78765408]\n",
      " [0.82681409]\n",
      " [0.83778702]\n",
      " [0.86140889]]\n",
      "Loss: \n",
      "0.35468265680615974\n",
      "\n",
      "Interation # 100\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.30357566]\n",
      " [0.60103473]\n",
      " [0.57256564]\n",
      " [0.55883323]]\n",
      "Loss: \n",
      "0.186581541889406\n",
      "\n",
      "Interation # 200\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.09535826]\n",
      " [0.81491198]\n",
      " [0.809652  ]\n",
      " [0.23016213]]\n",
      "Loss: \n",
      "0.03313943496456518\n",
      "\n",
      "Interation # 300\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.04733724]\n",
      " [0.89754125]\n",
      " [0.89924595]\n",
      " [0.12107718]]\n",
      "Loss: \n",
      "0.009387417859040908\n",
      "\n",
      "Interation # 400\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.03225335]\n",
      " [0.92619062]\n",
      " [0.93020885]\n",
      " [0.08462184]]\n",
      "Loss: \n",
      "0.004629940590192717\n",
      "\n",
      "Interation # 500\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02511183]\n",
      " [0.94096926]\n",
      " [0.94529955]\n",
      " [0.06649998]]\n",
      "Loss: \n",
      "0.0028824046517450354\n",
      "\n",
      "Interation # 600\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.02093928]\n",
      " [0.95007532]\n",
      " [0.95419049]\n",
      " [0.05565233]]\n",
      "Loss: \n",
      "0.0020316547659499857\n",
      "\n",
      "Interation # 700\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01817955]\n",
      " [0.95629277]\n",
      " [0.96009168]\n",
      " [0.0483907 ]]\n",
      "Loss: \n",
      "0.001543787924265674\n",
      "\n",
      "Interation # 800\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01620301]\n",
      " [0.96083614]\n",
      " [0.9643274 ]\n",
      " [0.04315666]]\n",
      "Loss: \n",
      "0.0012328443462810532\n",
      "\n",
      "Interation # 900\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01470775]\n",
      " [0.96431989]\n",
      " [0.9675373 ]\n",
      " [0.03918303]]\n",
      "Loss: \n",
      "0.0010196312636516984\n",
      "\n",
      "Interation # 1000\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01353077]\n",
      " [0.96708838]\n",
      " [0.97006787]\n",
      " [0.03604874]]\n",
      "Loss: \n",
      "0.0008654250997637354\n",
      "\n",
      "Interation # 1100\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01257608]\n",
      " [0.96934989]\n",
      " [0.97212348]\n",
      " [0.03350326]]\n",
      "Loss: \n",
      "0.0007492888867538537\n",
      "\n",
      "Interation # 1200\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.0117833 ]\n",
      " [0.97123797]\n",
      " [0.97383281]\n",
      " [0.03138794]]\n",
      "Loss: \n",
      "0.0006590062331032655\n",
      "\n",
      "Interation # 1300\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01111247]\n",
      " [0.97284238]\n",
      " [0.97528109]\n",
      " [0.02959722]]\n",
      "Loss: \n",
      "0.0005870108188954788\n",
      "\n",
      "Interation # 1400\n",
      "\n",
      "Input: \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output: \n",
      "[[0.01053602]\n",
      " [0.97422577]\n",
      " [0.97652719]\n",
      " [0.02805804]]\n",
      "Loss: \n",
      "0.0005283862312356267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "X = np.array(([0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]), dtype=float)\n",
    "y = np.array(([0], [1], [1], [0]), dtype=float)\n",
    "\n",
    "# Training the model\n",
    "NN = NeuralNetwork(X, y)\n",
    "for i in range(1500):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Interation # \" + str(i) + \"\\n\")\n",
    "        print(\"Input: \\n\" + str(X))\n",
    "        print(\"Actual Output: \\n\" + str(y))\n",
    "        print(\"Predicted Output: \\n\" + str(NN.feedforward()))\n",
    "        print(\"Loss: \\n\" + str(np.mean(np.square(y - NN.feedforward())))) # mean sum squared loss\n",
    "        print()\n",
    "    \n",
    "    NN.train(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
